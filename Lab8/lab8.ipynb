{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Виконання"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основне завдання"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'bbc-news-data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnltk\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mbbc-news-data.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, sep\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      6\u001b[0m df\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'bbc-news-data.csv'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "df = pd.read_csv('bbc-news-data.csv', sep='\\t')\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Зчитування файлу*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Видалимо колонки 'filename', 'title', 'category'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quarterly profits at US media giant TimeWarne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The dollar has hit its highest level against ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The owners of embattled Russian oil giant Yuk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>British Airways has blamed high fuel prices f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shares in UK drinks and food firm Allied Dome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>BT is introducing two initiatives to help bea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>Computer users across the world continue to i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>A new European directive could put software w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>The man making sure US computer networks are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>Online role playing games are time-consuming,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content\n",
       "0      Quarterly profits at US media giant TimeWarne...\n",
       "1      The dollar has hit its highest level against ...\n",
       "2      The owners of embattled Russian oil giant Yuk...\n",
       "3      British Airways has blamed high fuel prices f...\n",
       "4      Shares in UK drinks and food firm Allied Dome...\n",
       "...                                                 ...\n",
       "2220   BT is introducing two initiatives to help bea...\n",
       "2221   Computer users across the world continue to i...\n",
       "2222   A new European directive could put software w...\n",
       "2223   The man making sure US computer networks are ...\n",
       "2224   Online role playing games are time-consuming,...\n",
       "\n",
       "[2225 rows x 1 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['filename', 'title', 'category'], axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Видалення колонок*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Видалимо порожні документи, якщо вони є."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quarterly profits at US media giant TimeWarne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The dollar has hit its highest level against ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The owners of embattled Russian oil giant Yuk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>British Airways has blamed high fuel prices f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shares in UK drinks and food firm Allied Dome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>BT is introducing two initiatives to help bea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>Computer users across the world continue to i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>A new European directive could put software w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>The man making sure US computer networks are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>Online role playing games are time-consuming,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content\n",
       "0      Quarterly profits at US media giant TimeWarne...\n",
       "1      The dollar has hit its highest level against ...\n",
       "2      The owners of embattled Russian oil giant Yuk...\n",
       "3      British Airways has blamed high fuel prices f...\n",
       "4      Shares in UK drinks and food firm Allied Dome...\n",
       "...                                                 ...\n",
       "2220   BT is introducing two initiatives to help bea...\n",
       "2221   Computer users across the world continue to i...\n",
       "2222   A new European directive could put software w...\n",
       "2223   The man making sure US computer networks are ...\n",
       "2224   Online role playing games are time-consuming,...\n",
       "\n",
       "[2225 rows x 1 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[~(df.content.str.strip() == '')]\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Видалення порожніх документів*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визначимо стоп-слова англійської мови."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpt = nltk.WordPunctTokenizer()\n",
    "stop_words = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Стоп-слова*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визначимо функцію, що виконує попередню обробку документу. Застосуємо декоратор np.vectorize для того, щоб функція могла працювати з корпусами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['quarterly profits us media giant timewarner jumped bn three months december yearearlier firm one biggest investors google benefited sales highspeed internet connections higher advert sales timewarner said fourth quarter sales rose bn bn profits buoyed oneoff gains offset profit dip warner bros less users aol time warner said friday owns searchengine google internet business aol mixed fortunes lost subscribers fourth quarter profits lower preceding three quarters however company said aols underlying profit exceptional items rose back stronger internet advertising revenues hopes increase subscribers offering online service free timewarner internet customers try sign aols existing customers highspeed broadband timewarner also restate results following probe us securities exchange commission sec close concluding time warners fourth quarter profits slightly better analysts expectations film division saw profits slump helped boxoffice flops alexander catwoman sharp contrast yearearlier third final film lord rings trilogy boosted results fullyear timewarner posted profit bn performance revenues grew bn financial performance strong meeting exceeding fullyear objectives greatly enhancing flexibility chairman chief executive richard parsons said timewarner projecting operating earnings growth around also expects higher revenue wider profit margins timewarner restate accounts part efforts resolve inquiry aol us market regulators already offered pay settle charges deal review sec company said unable estimate amount needed set aside legal reserves previously set intends adjust way accounts deal german music publisher bertelsmanns purchase stake aol europe reported advertising revenue book sale stake aol europe loss value stake',\n",
       "       'dollar hit highest level euro almost three months federal reserve head said us trade deficit set stabilise alan greenspan highlighted us governments willingness curb spending rising household savings factors may help reduce late trading new york dollar reached euro thursday market concerns deficit hit greenback recent months friday federal reserve chairman mr greenspans speech london ahead meeting g finance ministers sent dollar higher earlier tumbled back worsethanexpected us jobs data think chairmans taking much sanguine view current account deficit hes taken time said robert sinche head currency strategy bank america new york hes taking longerterm view laying set conditions current account deficit improve year next worries deficit concerns china however remain chinas currency remains pegged dollar us currencys sharp falls recent months therefore made chinese export prices highly competitive calls shift beijings policy fallen deaf ears despite recent comments major chinese newspaper time ripe loosening peg g meeting thought unlikely produce meaningful movement chinese policy meantime us federal reserves decision february boost interest rates quarter point sixth move many months opened differential european rates halfpoint window believe could enough keep us assets looking attractive could help prop dollar recent falls partly result big budget deficits well uss yawning current account gap need funded buying us bonds assets foreign firms governments white house announce budget monday many commentators believe deficit remain close half trillion dollars',\n",
       "       'owners embattled russian oil giant yukos ask buyer former production unit pay back loan stateowned rosneft bought yugansk unit bn sale forced russia part settle bn tax claim yukos yukos owner menatep group says ask rosneft repay loan yugansk secured assets rosneft already faces similar repayment demand foreign banks legal experts said rosnefts purchase yugansk would include obligations pledged assets rosneft pay real money creditors avoid seizure yugansk assets said moscowbased us lawyer jamie firestone connected case menatep groups managing director tim osborne told reuters news agency default fight rule law exists international arbitration clauses credit rosneft officials unavailable comment company said intends take action menatep recover tax claims debts owed yugansk yukos filed bankruptcy protection us court attempt prevent forced sale main production arm sale went ahead december yugansk sold littleknown shell company turn bought rosneft yukos claims downfall punishment political ambitions founder mikhail khodorkovsky vowed sue participant sale',\n",
       "       ...,\n",
       "       'new european directive could put software writers risk legal action warns former programmer technology analyst bill thompson gets way dutch government conclude presidency european union pushing controversial measure rejected european parliament lacks majority support national governments leave millions european citizens legal limbo facing possibility court cases new law border controls defence even new constitution tv screens would full experts agonising impact daily lives sadly directly affected controversy concerns patenting computer programs topic may excite bloggers campaigning groups technical press obsess middle britain much fuss generate directive patentability computerimplemented inventions way amends article european patent convention yet new directive nodded next meeting one eus ministerial councils seems likely allow programs patented europe us many observers computing scene including think results disastrous small companies innovative programmers free open source software movement let large companies patent sorts ideas give legal force want limit competitors use really obvious ideas us cannot build system stores customer credit card details pay without reenter unless amazon lets hold patent oneclick online purchase small invention amazon made patent office first owns relatively free sort thing perhaps long new proposals go back although argument patentability software computerimplemented inventions going since least mids come head year proposals made endorsed council ministers radically modified european parliament represented original form national governments seem aware problems poland rejected proposal germanys main political parties opposed enough opposition guarantee rejection early december british government held consultation meeting commented proposals science minister lord sainsbury went along listen outline uk position according present embarrassing see little minister officials actually understood issues concerned draft directive put council called item approved rejected discussion amendment allowed worried first abuse democratic process involved disregarding views parliament abandoning carefully argued amendments goes heart european project even care software patents worried coders treated like today say tomorrow directly software patents granted programmer worry code writing infringing someone elses patent stealing software code already protected copyright patents copyright something much stronger patent gives owner right stop anyone else using invention even person invented separately never shame managed read lord byrons childe harolds pilgrimage pointed one articles contained substantial chunk poem could defend court claiming simply made coincidence hold patent sit afternoon write brilliant graphics compression routine happens lzw algorithm used gif files trouble patent law least us coincidence defence proposed directive supported many major software companies hardly surprising since usbased already cope legal environment allows patents legal departments crucially patents trade crosslicense patent holders even system breaks course microsoft found last year initially lost case brought eolas claimed internet explorer browsers infringed eolas patent one eventually thrown months uncertainty millions dollars small companies free open software movement patents trade much really useful software use every day programs like apache web server gnulinux operating system fearsomely popular firefox browser developed outside company structures people legal departments check patent infringements damage software happen overnight course directive goes written national laws steady stream legal actions small companies open source products eventually someone decide attack linux directly probably secret funding one two large players new directive limit innovation forcing programmers spend time checking patent infringements simply avoiding working potentially competitive areas damage europes computer industry hope council ministers integrity strength reject bad law bill thompson regular commentator bbc world service programme go digital',\n",
       "       'man making sure us computer networks safe secure resigned year post amit yoran director national cyber security division within us department homeland security created following attacks division tasked improving us defences malicious hackers viruses netbased threats reports suggest left division given enough clout within larger organisation mr yoran took post september first task get cyber security division running organisation staff people budget division charged thinking carrying action make us networks impervious attack disruption viruses worms hack attacks become commonplace last months mr yoran oversaw creation cyber alert system sends warnings big hitting viruses net attacks occur warnings also contained information firms organisations could protect attacks cyber security division also audited us government networks discover exactly sitting network next step creation scanning system identify vulnerabilities made federal networks machines susceptible attack malicious hackers virus writers mr yorans division also work identify networks machines broken cyber criminals despite success mr yoran left post abruptly end last week reportedly giving one days notice bosses department homeland security amit yoran valuable contributor cyber security issues past year appreciate efforts starting departments cybersecurity program said department homeland security spokeswoman reports suggested mr yoran felt frustrated lack prominence given work protect netbased threats wider homeland organisation attempt us politicians pass law promote mr yoran raise profile departments work mired congress',\n",
       "       'online role playing games timeconsuming enthralling flights reality people taking fantasy lives seriously video game world warcraft hit shops europe last week fans wrote bbc website express delight offer warning addiction game like far costly time substance could impair keep track time wrote travis anderson texas comments humorous game good im going get theres way could limit hours id spend playing wrote charles macintyre england struck worrying tone massively multiplayer online role playing game mmorpg need get could motto mmorpg shame getting popular know problem going mushroom wrote stuart stantondavies huddersfield scaremongering articles addictive video games existed since days first game pong stopped everyone working atari offices gaming like pastime quickly become unhealthy obsession whether spending much time gym front television reading poetry unfortunately gaming addiction far easy association make however stories gamers spending hours day front video games becoming frequent impact families quite distressing massively multiplayer online role playing games mmorpgs allow thousands gamers share common experience sharing fantasy science fiction worlds scope games like warcraft everquest ultima among others epic exploration adventure almost infinite part problem grinding gamers perform longwinded mindless tasks bring levels gain access adventure openendedness brings desire keep playing reason everquest eq nicknamed evercrack e hayot writing culture blogzine print culture said recently used play online roleplaying game everquest lot lot mean probably hours week average weeks didnt work many hours says world online gaming behaviour wasnt unusual lots people knew game played eq much lie dont go work stuff home cancel refuse invitations dinner spend much less time watching tv good thing presumably wrote explaining everquest took time quit game says realised life fun everquest let us clear obsession rare huge growth online gaming means growth numbers people take passion hobby far almost people bought copy world warcraft first two days sale earlier month fraction descend obsessives thoughts families friends gamers affected everquest found one blog everquest daily grind jane runs website compiles chronicle heartrending stories actually convinced point people spend times mmoprgs reality said one unnamed correspondent anonymous wrote rare nights husband come bed time find used sleeping difficult get sleep another body laying next cant talk playing absolutely point doesnt hear distracted get ummm ya minutes ask question gaming widows become comedic term women shut male gamers least funny another correspondent wrote believe addicted online gaming cause depression restlessness even sadder today son five days old sad truth husband spent hours today playing warcraft game interact sweet tiny baby important quests waiting online video game fans often complain hobby misunderstood marginalised gaming becomes ever mainstream games ever immersive hiding place social problems wish hours week unusual think probably isnt hour stretch isnt surprising ive known people play hours stretch know people spending weeks holiday work playing warcraft know people would play evercrack shiftswaking take friends resume waiting item needed appear understand key sign addiction alter life around rather fit life standards many us addicts solution force stop playingor need make real life bit interesting sadly talk people becoming obsessed gaming find longing time join long term relationship years since began games become complex find less less time play marriage work main drag time think line playing game lot gaming addiction really quite distinct play games lot definately hours week dont go missing work commitments order play games year ago deleted every game computer rpgs worst real world fades worries sorround new magic staff mighty sword unlike books perhaps even tv gain absolutely nothing stop playing youre point started achievements hour session irretrievably locked game since youve gained nothing real world may well pile achievement fake one despite little monetary value rewards encouragement offered mmorpgs enough hook games hours daily business could learn leverage simply human need easily measurable progress recognition perhaps unhealthily obsessed simply need recognition achievements reality advice gaming widows cant beat em join em try playing . wants play well , well least \\' together somewhere ... addict cost relationship . still play , without guilt , hehe , long played one sitting ? morning till early hours next day , birds singing side hobble bath room cos bladder full pain , would hardly eat , perhaps toast , smoke endlessly drink . , thankfully fascination worn girlfriend still job . part online gaming give adiction illusory achievement , end sight keep going mirage ultimate . obsessive behaviour , course , always cause concern , always bothers articles gaming talk terms \" reality \". obviously , somebody spends thirty hours week playing everquest problem . problem , however , nothing dysfunctional sense reality . obsessive eq player consider game \" real \" - example - obsessive automotive tinkerer considers car human . mmorpgs unique danger , terms encouraging obsessive behaviour , create absorbing virtual world , rather easily accessed 24 / 7 . problem lie nature gaming , nature modern 24 hour culture . problem called mmorpgs never really complete , \\' always another quest . friends 10 hours sleep since released friday ... championship manager consumed life years . one particular session started 2pm sunday , paused brief sleep 5am monday visit university classes restarted midday another 10 hour session . people tend hark problems \" hardcore gaming \" seem rarely allowed become immersed game . would expect perspective change . used everquest addict college . came point gaming world felt real real one . failed alot courses able barely graduate . lucky came senses , others less fortunate dropped college . holding job , avoid online rpgs like plague . made redundant told partner new job three months whilst every day played everquest 7 : 30am till 5 : pm . came home pretended got well , hence justifying playing evening . since quit playing mmorpg good job . got point eating dinner front pc realised things getting silly \\' trying spend much time . \\' easy . feel \\' got real addiction going . problem love complete goal . completed , finished , time move . become obsessed complete goal , standpoint addiction . game never complete \" ultimate \" goal , well would like falling black pit . easier escape controlled fantasy world face reality times - words goal offered pc game \" easier \" fun real world . pretty scary implications think . \\' buy world warcraft would destroy marrage , know !! played star wars galaxies year attest addictiveness games . engineered way early game progress quickly , progress becomes exponentially slower , requiring time reach next level . \\' sad say peak addiction spending entire weekends front monitor , slowly building character , stopping food toilet breaks . thankfully made clean break , actually managed sell jedi account £ 800 - sanity check otherwise completely unproductive time vacuum . seven years ago , began playing ultima online . game dominated 2 years life . 2 wonderful years still vivid memories experiences friends . online gaming world escapism without fear thoughts others . something cannot always achieved day day running normal life . whilst would warn people giving much life games , believe better way spend time say watching tv . gaming addictive made recognised addiction . single used play upto eight hours night work every night year , building stats , completing evermore quests battling ogres . somehow found time get , even met someone got married ! life changed ? hell ! still cast spells battle till early hours morning . fun ! online gaming enjoyed much would enjoy watching television , going cinema pub mates . many people use recreational drugs occasional basis able lead succesfull lives families , relationships good careers . minority allow drugs take destroy lives become addicted . according article true mmorpgs . message government clear , either legalise drugs , outlaw online gaming !! sounds like sad stories - believe . play alot warcraft , know full well addictive . resolute take life . certainly gets way though . think people simply know draw line , lack willpower stop stepping . think \\' obsessed gaming general , spend far much time playing games like everquest 2 football manager rather going interacting real people try , \\' always thinking back mind \\' rather front computer winning league cambridge united . obsessed online role playing games . \\' much quests adrenaline real life situation - goals achieve etc . spend five hours per day online playing rarely get four five hours sleep getting work next morning ... many players spend time mmorpgs rather front tv fail see affect players social lives negatively . furthermore types games contain huge social aspect , whereas games pursuits ( couch potato ) players could indulging solitary nature . games like things -- much anything bad thing , long walk away computer things , great fun . living korea moment , lots pc bangs ( internet cafes ). nearly south koreans addicted online games , one korean died lack food water playing online games . play xbox live every day . find self lying rescheduling everything around gaming fix . longest played 24 hour straight session . know play long \\' obsession \\' control . reccomend counsellor - wind ... something \\' increasingly concerned ... mate play online hour two day , \\' aware much time disappear sitting front tv , trying \\' frag \\' individual . \\' getting balance getting home relasing stress day hour gaming , enjoying \\' real \\' life ... bought us version world warcraft came . longest period played 23 hrs straight . gave game month addictive , subsequently bought european version ( \\' help ). future , \\' going regulate time far strictly . great game ! played mmorpg games years agree type games life sucking . concern younger generation gamers play hours end adult enviroment . mmorpg games need credit card play dont think parents know letting children . unless undeniable medical proof staring computer screens hours time damage person &# 191 ; health , expect decline get worse . people pathetic . need get machines notice world swiftly overcome issues troubles make trifling worries \" online universe \" absolutely meaningless . 24hours , kid school half term , ultima online game , ahhhh days ! lol'],\n",
       "      dtype='<U16917')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@np.vectorize\n",
    "def preproc_doc(doc):\n",
    "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I | re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    tokens = wpt.tokenize(doc)\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "p_corpus = preproc_doc(df.content)\n",
    "p_corpus"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Обробка документів*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Розіб'ємо кожний документ на окремі слова, об'єднаємо усі слова в одну сукупність."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>freeflowing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>foxed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recourses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>christie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cigarettes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>shiner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sahundi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dawns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>zodiac</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         words\n",
       "0  freeflowing\n",
       "1        foxed\n",
       "2         weak\n",
       "3    recourses\n",
       "4     christie\n",
       "5   cigarettes\n",
       "6       shiner\n",
       "7      sahundi\n",
       "8        dawns\n",
       "9       zodiac"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words = []\n",
    "for doc in p_corpus:\n",
    "    df_words.extend(doc.split(' '))\n",
    "df_words = pd.DataFrame(set(df_words))\n",
    "df_words.columns = ['words']\n",
    "df_words.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Розбиття на слова*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визначимо частину мови для кожного слова. Використаємо функцію nltk.pos_tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>ps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>freeflowing</td>\n",
       "      <td>VBG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>foxed</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weak</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recourses</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>christie</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31333</th>\n",
       "      <td>telecast</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31334</th>\n",
       "      <td>orqueras</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31335</th>\n",
       "      <td>eavesdrop</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31336</th>\n",
       "      <td>redesigning</td>\n",
       "      <td>VBG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31337</th>\n",
       "      <td>builder</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31338 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             words   ps\n",
       "0      freeflowing  VBG\n",
       "1            foxed   JJ\n",
       "2             weak   JJ\n",
       "3        recourses  NNS\n",
       "4         christie  VBP\n",
       "...            ...  ...\n",
       "31333     telecast  VBP\n",
       "31334     orqueras   JJ\n",
       "31335    eavesdrop   NN\n",
       "31336  redesigning  VBG\n",
       "31337      builder   NN\n",
       "\n",
       "[31338 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words['ps'] = [tag for _, tag in nltk.pos_tag(df_words.words)]\n",
    "df_words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Визначення частини мови*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Узагальнимо частини мови до звичайних: noun, adective, verb тощо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>ps</th>\n",
       "      <th>sps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>freeflowing</td>\n",
       "      <td>VBG</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>foxed</td>\n",
       "      <td>JJ</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weak</td>\n",
       "      <td>JJ</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recourses</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>christie</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31333</th>\n",
       "      <td>telecast</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31334</th>\n",
       "      <td>orqueras</td>\n",
       "      <td>JJ</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31335</th>\n",
       "      <td>eavesdrop</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31336</th>\n",
       "      <td>redesigning</td>\n",
       "      <td>VBG</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31337</th>\n",
       "      <td>builder</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31338 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             words   ps   sps\n",
       "0      freeflowing  VBG  VERB\n",
       "1            foxed   JJ   ADJ\n",
       "2             weak   JJ   ADJ\n",
       "3        recourses  NNS  NOUN\n",
       "4         christie  VBP  VERB\n",
       "...            ...  ...   ...\n",
       "31333     telecast  VBP  VERB\n",
       "31334     orqueras   JJ   ADJ\n",
       "31335    eavesdrop   NN  NOUN\n",
       "31336  redesigning  VBG  VERB\n",
       "31337      builder   NN  NOUN\n",
       "\n",
       "[31338 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag import map_tag\n",
    "df_words['sps'] = [map_tag('en-ptb', 'universal', tag) for tag in df_words.ps]\n",
    "df_words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Узагальнення чатин мов*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Перетворимо узагальнені частини мови на абревіатури для лематизації."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>ps</th>\n",
       "      <th>sps</th>\n",
       "      <th>abbr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>freeflowing</td>\n",
       "      <td>VBG</td>\n",
       "      <td>VERB</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>foxed</td>\n",
       "      <td>JJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weak</td>\n",
       "      <td>JJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recourses</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>christie</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VERB</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31333</th>\n",
       "      <td>telecast</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VERB</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31334</th>\n",
       "      <td>orqueras</td>\n",
       "      <td>JJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31335</th>\n",
       "      <td>eavesdrop</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31336</th>\n",
       "      <td>redesigning</td>\n",
       "      <td>VBG</td>\n",
       "      <td>VERB</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31337</th>\n",
       "      <td>builder</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31338 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             words   ps   sps abbr\n",
       "0      freeflowing  VBG  VERB    v\n",
       "1            foxed   JJ   ADJ    a\n",
       "2             weak   JJ   ADJ    a\n",
       "3        recourses  NNS  NOUN    n\n",
       "4         christie  VBP  VERB    v\n",
       "...            ...  ...   ...  ...\n",
       "31333     telecast  VBP  VERB    v\n",
       "31334     orqueras   JJ   ADJ    a\n",
       "31335    eavesdrop   NN  NOUN    n\n",
       "31336  redesigning  VBG  VERB    v\n",
       "31337      builder   NN  NOUN    n\n",
       "\n",
       "[31338 rows x 4 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abbr = {'NOUN': 'n', 'VERB': 'v', 'ADJ': 'a', 'ADV': 'r'}\n",
    "def to_abbr(el):\n",
    "    res = abbr.get(el)\n",
    "    if res is not None:\n",
    "        return res\n",
    "    return ''\n",
    "\n",
    "df_words['abbr'] = [to_abbr(x) for x in df_words.sps]\n",
    "df_words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Приведення загальних частин мов до абревіатур*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проведемо лематизацію кожного слова за допомогою методу lemmatize об'єкта класу nltk.stem.WordNetLemmatizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>ps</th>\n",
       "      <th>sps</th>\n",
       "      <th>abbr</th>\n",
       "      <th>lemms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>freeflowing</td>\n",
       "      <td>VBG</td>\n",
       "      <td>VERB</td>\n",
       "      <td>v</td>\n",
       "      <td>freeflowing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>foxed</td>\n",
       "      <td>JJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>a</td>\n",
       "      <td>foxed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weak</td>\n",
       "      <td>JJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>a</td>\n",
       "      <td>weak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recourses</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>n</td>\n",
       "      <td>recourse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>christie</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VERB</td>\n",
       "      <td>v</td>\n",
       "      <td>christie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31333</th>\n",
       "      <td>telecast</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VERB</td>\n",
       "      <td>v</td>\n",
       "      <td>telecast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31334</th>\n",
       "      <td>orqueras</td>\n",
       "      <td>JJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>a</td>\n",
       "      <td>orqueras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31335</th>\n",
       "      <td>eavesdrop</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>n</td>\n",
       "      <td>eavesdrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31336</th>\n",
       "      <td>redesigning</td>\n",
       "      <td>VBG</td>\n",
       "      <td>VERB</td>\n",
       "      <td>v</td>\n",
       "      <td>redesign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31337</th>\n",
       "      <td>builder</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>n</td>\n",
       "      <td>builder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31338 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             words   ps   sps abbr        lemms\n",
       "0      freeflowing  VBG  VERB    v  freeflowing\n",
       "1            foxed   JJ   ADJ    a        foxed\n",
       "2             weak   JJ   ADJ    a         weak\n",
       "3        recourses  NNS  NOUN    n     recourse\n",
       "4         christie  VBP  VERB    v     christie\n",
       "...            ...  ...   ...  ...          ...\n",
       "31333     telecast  VBP  VERB    v     telecast\n",
       "31334     orqueras   JJ   ADJ    a     orqueras\n",
       "31335    eavesdrop   NN  NOUN    n    eavesdrop\n",
       "31336  redesigning  VBG  VERB    v     redesign\n",
       "31337      builder   NN  NOUN    n      builder\n",
       "\n",
       "[31338 rows x 5 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wlem = WordNetLemmatizer()\n",
    "def my_lem(word, abbr):\n",
    "    if abbr == '':\n",
    "        return wlem.lemmatize(word)\n",
    "    return wlem.lemmatize(word, pos=abbr)\n",
    "df_words['lemms'] = [my_lem(row[1]['words'], row[1]['abbr']) \n",
    "               for row in df_words.loc[:, ['words', 'abbr']].iterrows()]\n",
    "df_words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Лематизація слів*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Представимо корпус як модуль \"Сумка слів\". Використаємо для цього клас CountVectorizer зі sklearn.feature_extraction.text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(min_df=0., max_df=1.)\n",
    "cv_matrix = cv.fit_transform(p_corpus)\n",
    "cv_matrix = pd.DataFrame(cv_matrix.toarray(), \n",
    "                         columns=cv.get_feature_names_out())\n",
    "cv_matrix.to_csv('bag_of_words.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Сумка слів*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Представимо корпус як модель TD-IDF. ### Перетворимо матрицю з частотою термінів на матрицю tfidf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>05</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>125</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>zooropa</th>\n",
       "      <th>zornotza</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zubair</th>\n",
       "      <th>zuluaga</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zurichs</th>\n",
       "      <th>zutons</th>\n",
       "      <th>zvonareva</th>\n",
       "      <th>zvyagintsev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows × 31266 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       00  000   05    10  100   11   12  125   13   14  ...  zooropa  \\\n",
       "0     0.0  0.0  0.0  0.00  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n",
       "1     0.0  0.0  0.0  0.00  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n",
       "2     0.0  0.0  0.0  0.00  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n",
       "3     0.0  0.0  0.0  0.00  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n",
       "4     0.0  0.0  0.0  0.00  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n",
       "...   ...  ...  ...   ...  ...  ...  ...  ...  ...  ...  ...      ...   \n",
       "2220  0.0  0.0  0.0  0.00  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n",
       "2221  0.0  0.0  0.0  0.00  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n",
       "2222  0.0  0.0  0.0  0.00  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n",
       "2223  0.0  0.0  0.0  0.00  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n",
       "2224  0.0  0.0  0.0  0.04  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n",
       "\n",
       "      zornotza  zorro  zubair  zuluaga  zurich  zurichs  zutons  zvonareva  \\\n",
       "0          0.0    0.0     0.0      0.0     0.0      0.0     0.0        0.0   \n",
       "1          0.0    0.0     0.0      0.0     0.0      0.0     0.0        0.0   \n",
       "2          0.0    0.0     0.0      0.0     0.0      0.0     0.0        0.0   \n",
       "3          0.0    0.0     0.0      0.0     0.0      0.0     0.0        0.0   \n",
       "4          0.0    0.0     0.0      0.0     0.0      0.0     0.0        0.0   \n",
       "...        ...    ...     ...      ...     ...      ...     ...        ...   \n",
       "2220       0.0    0.0     0.0      0.0     0.0      0.0     0.0        0.0   \n",
       "2221       0.0    0.0     0.0      0.0     0.0      0.0     0.0        0.0   \n",
       "2222       0.0    0.0     0.0      0.0     0.0      0.0     0.0        0.0   \n",
       "2223       0.0    0.0     0.0      0.0     0.0      0.0     0.0        0.0   \n",
       "2224       0.0    0.0     0.0      0.0     0.0      0.0     0.0        0.0   \n",
       "\n",
       "      zvyagintsev  \n",
       "0             0.0  \n",
       "1             0.0  \n",
       "2             0.0  \n",
       "3             0.0  \n",
       "4             0.0  \n",
       "...           ...  \n",
       "2220          0.0  \n",
       "2221          0.0  \n",
       "2222          0.0  \n",
       "2223          0.0  \n",
       "2224          0.0  \n",
       "\n",
       "[2225 rows x 31266 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tt = TfidfTransformer(norm='l2', use_idf=True)\n",
    "tt_matrix = tt.fit_transform(cv_matrix)\n",
    "tt_matrix = tt_matrix.toarray()\n",
    "vocab = cv.get_feature_names_out()\n",
    "tv_matrix = pd.DataFrame(np.round(tt_matrix, 2), columns=vocab)\n",
    "tv_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Матриця TF-IDF*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_matrix."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
